<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GenAI Robo</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <style>
        body { 
            font-family: Arial, sans-serif; 
            margin: 0; 
            padding: 0; 
            background-color: #f2f2f2; 
        }
        .chat-container { 
            position: fixed; 
            top: 0vh; 
            left: 0vw;
            width: 100vw; 
            height: 100vh; 
            display: flex; 
            flex-direction: column; 
            background-color: #c0c0c0; 
            border: 1px solid #ccc; 
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
		
		.mic-icon-container {
			background-color: #f8f8f8; 
			display: flex;
			justify-content: center; /* Center horizontally */
			align-items: center; /* Center vertically */
			flex-grow: 0;
		}
		
        .chat-log { 
            overflow-y: auto; 
            padding: 15px; 
            flex-grow: 1; 
        }
        .chat-message { 
            display: flex; 
            align-items: center; 
            margin-bottom: 15px; 
            font-size: 18px; 
        }
        .message-content { 
            padding: 10px 20px; 
            border-radius: 20px; 
            max-width: 70%; 
            font-family: sans-serif; 
        }
        .bot-message { 
            justify-content: flex-start; 
        }
		.bot-message .message-content { 
		background-color: #b3d9ff; 
		color: #333; 
		margin-right: 10px; 
		border-radius: 20px;
		}
        .user-message { 
            justify-content: flex-end; 
        }
        .user-message .message-content { 
            background-color: #ccffcc; 
            color: #333; 
            margin-left: 10px; 
            border-radius: 20px;
        }
        .fa-kai, .fa-user {
            font-size: 30px; 
            padding: 10px; 
            border-radius: 50%; 
            color: #fff;
        }
        .fa-kai {
			background-image: url('/KAIIcon.png'); /* Path to your custom icon */
			background-size: cover; /* Resize the image to fit the element */
			background-repeat: no-repeat;
			background-position: center;
			margin-right: 10px;
			width: 30px; /* Adjust size as needed */
			height: 30px; /* Adjust size as needed */
        }
        .fa-user {
            background-color: #b4f0b4; 
            margin-left: 10px;
        }
        .chat-input { 
            #padding: 15px;
            padding: 0px;
            background-color: #fff; 
            border-top: 1px solid #ddd; 
            display: flex;
        }
        input[type="text"] { 
            flex-grow: 1; 
            padding: 10px; 
            margin-right: 10px; 
            border: 1px solid #ccc; 
        }
        .send-btn { 
            background-color: #007bff; 
            color: white; 
            border: none; 
            padding: 10px 15px; 
            cursor: pointer; 
            font-size: 16px; 
        }
        .send-btn i { 
            margin-right: 5px; 
        }
		@keyframes blink {
			0% { opacity: .2; }
			20% { opacity: 1; }
			100% { opacity: .2; }
		}
		.typing-indicator {
			font-size: 18px;
			display: inline-block;
			margin-left: 4px;
			animation: blink 1.4s infinite;
		}

		.mic-icon {
			position: relative;
			//width: 250px; /* Diameter of the circle */
			width: 100%;
			height: 100px; /* Diameter of the circle */
			//background-color: #0048E6; /* Blue */
			background-color: #f44336; /* Red */
			border-radius: 0%; /* Makes the button a circle */
			border: none;
			cursor: pointer;
			display: flex;
			justify-content: center;
			align-items: center;
			margin-right: 0px;
		}
		
		.mic-icon::before {
			content: "";
			position: absolute;
			top: 35px;
			width: 15px; /* Width of the microphone part */
			height: 20px; /* Height of the microphone part */
			background-color: white;
			border-radius: 50%;
		}
		
		.mic-icon::after {
			content: "";
			position: absolute;
			bottom: 40px;
			width: 15px; /* Width of the base part */
			height: 5px; /* Height of the base part */
			background-color: white;
			border-radius: 10px;
		}
		
		
		/* Base button styling */
		#start-voice-recognition {
			background-color: #4CAF50; /* Green background */
			color: white; /* White text */
			padding: 15px 32px; /* Padding inside the button */
			text-align: center; /* Centered text */
			text-decoration: none; /* No underline on the text */
			display: inline-block; /* Display as inline-block */
			font-size: 16px; /* Font size */
			margin: 4px 2px; /* Margin around the button */
			cursor: pointer; /* Cursor pointer on hover */
			border: none; /* No border */
			border-radius: 8px; /* Rounded corners */
			transition: background-color 0.3s; /* Smooth background color transition */
		}
		
		/* Button styling when the app is listening */
		#start-voice-recognition.listening {
			background-color: #f44336; /* Change to red background */
		}

		/* dataset selector */
		#dataset {
			font-size: 1.2em;
			padding: 10px;
			width: 100%;
			max-width: 300px;
		}

    </style>
</head>
<body>

<div class="chat-container">

	<select id="dataset" onchange="saveSelection()" hidden>
		 <option value="confidential">Dataset: confidential</option>
		 <option value="sustainability-1">Dataset: sustainability-1</option>
		 <option value="qualitytest">Dataset: qualitytest</option>
	</select>

    <div class="chat-log" id="chatLog">
        <div class="chat-message bot-message">
            <i class="fas fa-kai"></i>
            <div class="message-content">
			
			Hello! I am Hitachi Rail GenAI Robot.<br>
			<br>
			You can ask anything you want to know about Hitachi Rail.<br>
			<br>
			<!--
			Examples -
			<ul>
			<li>What is the phone number of this factory?</li>
			<li>Give me the address of this factory.</li>
			<li>Introduce the emegency plan.</li>
			</ul>
			-->
			Any language is acceptable for me.<br>
			<br>
			How can I help you?
			
			</div>
        </div>
    </div>
	
	<div class="mic-icon-container">
		<button class="mic-icon" id="mic-button"></button>
	</div>
	
    <!-- <div class="chat-input" hidden> -->
    <div class="chat-input">
		<!-- <button class="mic-icon" id="start-btn"></button>  in case of Web Speech API -->		
        <input type="text" id="userInput" placeholder="Type your message here..." onkeypress="handleKeyPress(event)" hidden>
        <button class="send-btn" onclick="sendMessage()" hidden><i class="fas fa-paper-plane"></i>Send</button>
		
		<!--
        <input type="text" id="userInput" placeholder="Type your message here..." onkeypress="handleKeyPress(event)">
        <button class="send-btn" onclick="sendMessage()"><i class="fas fa-paper-plane"></i>Send</button>
		-->
		
		
    </div>
	
	<script src="encode-audio.js"></script>
	<!-- Audio test for debug -->
	<!--
    <div>
		<audio controls id="audio"></audio>
    </div>
	-->
	
	<!-- <button id="start-voice-recognition">Start Voice Recognition</button> -->
	
	<!-- <audio controls src="http://localhost/test.mp3" type="audio/mp3"> -->
	
</div>

<script>

	// Save the option
	// Add the saved option
	window.addEventListener('DOMContentLoaded', () => {
		const selectedDataset = localStorage.getItem('selectedDataset');
		console.log(selectedDataset);
		if (selectedDataset) {
			document.getElementById('dataset').value = selectedDataset;
		} else {
			datasetSelect.selectedIndex = 0;
		}
	});
	// Save the selected option to local storage
	function saveSelection() {
		const datasetSelect = document.getElementById('dataset');
		localStorage.setItem('selectedDataset', datasetSelect.value);
	}

	// Chat box
	const textbox = document.getElementById('userInput');
    const wsurl = `wss://${location.hostname}:${location.port}`;
	const ws = new WebSocket(wsurl);
		
	let audio = new Audio();
	let isPlaying = false;   // True if audio is playing
	let isRecording = false; // True if recording is activated
	
	let isWaiting = false;  // True if waiting response from LLM
	
	try {
		ws.onopen = function(e) {
			console.log("Websocket Connection established");
			// Display thinking animation until recieving msg
		};
		
		ws.onmessage = function(event) {
			removeTypingIndicator();
			console.log('Message from server:', event.data);
			const res = JSON.parse(event.data);
			var msg = res['response'];
			
			// Replace the message
			displayMessage(msg, 'bot');
			
			// Speech the Voice
			const speechData = res['speech'];
			
			//console.log(speechData.data);
			//console.log(speechData.type);	
			
			vblob = new Blob([Uint8Array.from(atob(speechData.data), c => c.charCodeAt(0))], { type: speechData.type });
			
			const audioUrl = URL.createObjectURL(vblob);
			audio = new Audio(audioUrl);
			
			console.log(audio);
			
			// Disable Waiting flag here
			isWaiting = false;
			
			audio.addEventListener('playing', () => {
				isPlaying = true;
			});
			
			function playAudio() {
				audio.play()
					.catch(error => 
						console.log('Error playing audio:', error)
					);
			}
			playAudio();

			audio.addEventListener('ended', () => { 
				console.log('Audio playback ended');
				isPlaying = false;
				URL.revokeObjectURL(audioUrl);
			});
		};
		
		ws.onerror = function(error) {
			console.log('WebSocket error:', error);
		};
		
		
	} catch (error) {
		console.error("WebSocket Connection error:", error);
	}

	
	// Sleep Timer
	function sleep(ms) {
		return new Promise((resolve) => setTimeout(resolve, ms));
	}

	// Send Message
    function sendMessage() {
        var inputField = document.getElementById("userInput");
        var message = inputField.value.trim();
		
		var inputField = document.getElementById("dataset");
		var dataset = inputField.value.trim();


		// Backup the selection of dataset
		let datasetSelect = document.getElementById('dataset');
		let selectedDataset = datasetSelect.value;

		localStorage.setItem('selectedDataset', selectedDataset);
		setTimeout(() => {
			const previousSelection = localStorage.getItem('selectedDataset');
			if (previousSelection) {
				datasetSelect.value = previousSelection;
			}
			}, 0
		);
		
		removeUserTypingIndicator();	// Remove Typing Indicator
        if (message !== "") {		
			if (dataset === "") {
				dataset = 'confidential';
			}
            displayMessage(message, 'user'); // Display the user message
            ws.send(JSON.stringify({ prompt: message, dataset: dataset })); // Send the message
            displayTypingIndicator(); // Display the typing indicator after sending a message
            inputField.value = ""; // Clear input field
			isWaiting = true;
        }
    }

    function handleKeyPress(event) {
        if (event.key === "Enter") {
            sendMessage();
            event.preventDefault(); // Prevent the default action (form submission)
        }
    }

    function displayMessage(message, sender) {
        var chatLog = document.getElementById("chatLog");
        var messageElement = document.createElement("div");
        messageElement.classList.add("chat-message", sender + "-message");

        var contentElement = document.createElement("div");
        contentElement.classList.add("message-content");

        //contentElement.textContent = message;  //disable HTML
		//contentElement.innerHTML = message;
		let index = 0;
		let isTag = false;
		let tagContent = '';
		
		// Function to display message with typing animation
        function type() {
            if (index < message.length) {
				const c = message.charAt(index)
				
				// Check if we are inside an HTML tag
				if (c === '<') {
					isTag = true;
				}
				
				if (isTag) {
					tagContent += c;
					if (c === '>') {
						isTag = false;
						contentElement.innerHTML += tagContent;
						tagContent = '';
					}
				} else {
					contentElement.innerHTML += c;
				}
			}
			index++;
            setTimeout(type, 20); // Delay between each character
			
			// Scroll to Bottom
			chatLog.scrollTop = chatLog.scrollHeight; 
			
        }
		
		if (sender === 'user') {
			contentElement.innerHTML = message;
		} else {
			type();
		}

        if (sender === 'user') {
            var iconElement = document.createElement("i");
			messageElement.appendChild(contentElement);
            iconElement.classList.add("fas", "fa-user");
            messageElement.appendChild(iconElement);            
        } else {
            var iconElement = document.createElement("i");
            iconElement.classList.add("fas", "fa-kai");
			messageElement.appendChild(iconElement);
            messageElement.appendChild(contentElement);
       }

        chatLog.appendChild(messageElement);
        chatLog.scrollTop = chatLog.scrollHeight; // Scroll to the bottom
    }
	
	// User typing indicator
    function displayUserTypingIndicator() {
        var chatLog = document.getElementById("chatLog");
        var typingIndicator = document.createElement("div");
        typingIndicator.classList.add("chat-message", "user-message");
        typingIndicator.innerHTML = '<div class="message-content"><span class="typing-indicator">Recognizing your voice...</span></div><i class="fas fa-user"></i>';
        typingIndicator.id = "userTypingIndicator"; // Assign an ID for later removal
        chatLog.appendChild(typingIndicator);
        chatLog.scrollTop = chatLog.scrollHeight;
    }
	
    function removeUserTypingIndicator() {
        var typingIndicator = document.getElementById("userTypingIndicator");
        if (typingIndicator) {
            typingIndicator.parentNode.removeChild(typingIndicator);
        }
    }
	
	// Bot typing indicator
    function displayTypingIndicator() {
        var chatLog = document.getElementById("chatLog");
        var typingIndicator = document.createElement("div");
        typingIndicator.classList.add("chat-message", "bot-message");
        typingIndicator.innerHTML = '<i class="fas fa-kai"></i><div class="message-content"><span class="typing-indicator">...</span></div>';
        typingIndicator.id = "typingIndicator"; // Assign an ID for later removal
        chatLog.appendChild(typingIndicator);
        chatLog.scrollTop = chatLog.scrollHeight;
    }

    function removeTypingIndicator() {
        var typingIndicator = document.getElementById("typingIndicator");
        if (typingIndicator) {
            typingIndicator.parentNode.removeChild(typingIndicator);
        }
    }
	
	// Utility function to calculate volume from audio buffer
	function calculateVolume(buffer) {
		// Simple root mean square (RMS) to calculate volume
		let sum = 0;
		for (let i = 0; i < buffer.length; i++) {
			sum += buffer[i] * buffer[i];
		}
		return Math.sqrt(sum / buffer.length);
	}
	
	// Adjust according to environment
	const VOLUME_THRESHOLD = 18.0;  // Volume value (a.u.) to be adjusted
	const SILENCE_THRESHOLD_TIME = 5.0; // Sec
	
	// Audio recording
	async function audioMain() {
		try {
			const audioSelector = document.querySelector('#audio');
			let isRecording = false; // Track recording state
			let startRecordingTime = null; // To keep track of silence duration
	
			const stream = await navigator.mediaDevices.getUserMedia({
				video: false,
				audio: true,
			});
	
			const [track] = stream.getAudioTracks();
			const settings = track.getSettings();
	
			const audioContext = new AudioContext();
			await audioContext.audioWorklet.addModule('audio-recorder.js');
	
			const mediaStreamSource = audioContext.createMediaStreamSource(stream);
			const audioRecorder = new AudioWorkletNode(audioContext, 'audio-recorder');
			const buffers = [];
			
			// Set up the audio analyzer
			const analyzer = audioContext.createAnalyser();
			mediaStreamSource.connect(analyzer);
			analyzer.fftSize = 2048;
			const bufferLength = analyzer.frequencyBinCount;
			const dataArray = new Uint8Array(bufferLength);
			
			audioRecorder.port.addEventListener('message', event => {
				buffers.push(event.data.buffer);
			});
			
			audioRecorder.port.start();
	
	        mediaStreamSource.connect(audioRecorder);
	        audioRecorder.connect(audioContext.destination);
			
			// Start Recording
			function startRecording() {
				console.log('Voice activity detected. Starting recording.');				
				isRecording = true;				
				audioRecorder.parameters.get('isRecording').setValueAtTime(1, audioContext.currentTime);
				buffers.splice(0, buffers.length); // Clear old data
				
				displayUserTypingIndicator(); // Display typing indicator on User side				
			}
			
			// Stop Recording
			function stopRecording() {
				console.log('Silence detected. Stopping recording.');
				isRecording = false;
				audioRecorder.parameters.get('isRecording').setValueAtTime(0, audioContext.currentTime);
				
				// Generate WAV data
				const blob = encodeAudio(buffers, settings);
				const url = URL.createObjectURL(blob);
				
	            // Send to openAI API proxy
	            const formData = new FormData();
	            formData.append('file', blob, 'sample.wav');
	                
	            const fetchOptions = {
	                method: 'POST',
	                body: formData
	            };
	            	
	            fetch('/proxy', fetchOptions)
	                .then(response => response.json())
	                .then(data => {
	                    console.log(data);
	
	                    const inputField = document.getElementById("userInput");
	                    inputField.value = data.message;
						sendMessage();
	                        
	                }).catch(error => {
	                    console.error('/proxy POST Error:', error);
	                });
			};
			
			// Start voice activity detection
			let sum;
			let average;
			let isVoiceDetected;
			
			// Mic control Button (force stop)
			const micBtn = document.getElementById('mic-button');
			//micBtn.style.backgroundColor = '#0048E6'; // Blue
			//micBtn.style.backgroundColor = '#f44336'; // Red
			
			let pauseRecord = true;
			let manualStop = false;
			
			micBtn.addEventListener('click', function() {
			
				if (isPlaying == true) {
					audio.pause();
					isPlaying = false;
				} else {
					manualStop = !manualStop;
				}
				//console.log(`pauseRecord: ${pauseRecord}`);
				//console.log(`isPlaying: ${isPlaying}`);
				//console.log(`manualStop: ${manualStop}`);				
			});
			
			function detectVoice() {
			
				// If audio is playing
				if (isPlaying == true) {
					micBtn.style.backgroundColor = '#f44336'; // Red
					pauseRecord = true;
					
				} else {
				
					if (isWaiting == true) {
						micBtn.style.backgroundColor = '#f44336'; // Red
						pauseRecord = true;
						
					} else {
						if (manualStop == true) {
							micBtn.style.backgroundColor = '#f44336'; // Red
							pauseRecord = true;
						} else {
							micBtn.style.backgroundColor = '#0048E6'; // Blue
							pauseRecord = false;
						}
					}					
				}
			
				if (pauseRecord == false) {
			
					analyzer.getByteFrequencyData(dataArray);
					sum = dataArray.reduce((acc, val) => acc + val, 0);
					average = sum / bufferLength;
					
					// [DEBUG] To adjust the volume
					//console.log(`average rate: ${average}`)
					
					isVoiceDetected = average > VOLUME_THRESHOLD;
					
					// [DEBUG] 
					//console.log(`isVoiceDetected ${isVoiceDetected} !isRecording ${isRecording} && !isPlaying ${isPlaying}`);
					
					if (isVoiceDetected && !isRecording) {
						if (!isPlaying){							
							startRecording();
							startRecordingTime = audioContext.currentTime;
							
						} else {
							// Force stop the current playing
							//audio.pause();
							//startRecording();
							//startRecordingTime = audioContext.currentTime;
						}				
					} else if (!isVoiceDetected && isRecording) {
						// Check if the silence has lasted for the threshold duration
						
						//console.log(`Silent Time: ${audioContext.currentTime - startRecordingTime}`)
						
						if (audioContext.currentTime - startRecordingTime >= SILENCE_THRESHOLD_TIME) {
							stopRecording();
						}
					}			
				}
				//console.log(`pauseRecord: ${pauseRecord}`)
				requestAnimationFrame(detectVoice);
			}
			
			detectVoice();
			
			} catch (err) {
				console.error('Error in audio setup:', err);
			}			
			
	}
	audioMain();
	
	
	// Speech recognition (use Web Speech API)
	function webSpeechAPIMain() {
		let recognition;
		let recognizing = false; // A flag to indicate whether recognition is active
		const startBtn = document.getElementById('start-btn');
		
		if ('webkitSpeechRecognition' in window) {
		
			console.log("Try speaking into the microphone.");
			
			recognition = new webkitSpeechRecognition();
			recognition.continuous = true;
			recognition.interimResults = true;
			recognition.lang = 'en-US';
			
			recognition.onstart = function() {
			recognizing = true;
			console.log('Voice recognition started. Speak into the microphone.');
			startBtn.style.backgroundColor = '#f44336';
			}
			
			recognition.onerror = function(event) {
			console.log('Speech recognition error', event);
			};
			
			recognition.onend = function() {
			recognizing = false;
			console.log('Voice recognition stopped.');
			startBtn.style.backgroundColor = '#0048E6'; // Change button color back to indicate inactive recognition
			};
			
			recognition.onresult = function(event) {
			let transcript = '';
			for (let i = event.resultIndex; i < event.results.length; ++i) {
				transcript += event.results[i][0].transcript;
			}
			textbox.value = transcript;
			};
			
			startBtn.addEventListener('click', function() {
			if (recognizing) {
				recognition.stop();
			} else {
				recognition.start();
			}	
			});
	
		} else {
			alert('Your browser does not support speech recognition.');
			startBtn.disabled = true;
		}
	}
	
	// Comment out if use Web Speech API
	//webSpeechAPIMain()
	
</script>

</body>
</html>

